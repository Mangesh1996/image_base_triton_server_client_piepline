docker run --gpus 1 --rm --shm-size=1g --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -p 8000:8000 -p 8001:8001 -p 8002:8002 -v $(pwd)/model_respository:/models nvcr.io/nvidia/tritonserver:21.06-py3  tritonserver \
--model-repository=/models --strict-model-config=false --grpc-infer-allocation-pool-size=16 --log-verbose=1 

cd Desktop/Desktop_Items/nvidia_triton_server/trion_work/tao_triton/python/entrypoints

python3 tao_client.py ~/Desktop/Desktop_Items/nvidia_triton_server/trion_work/input_image -m fire --class_list fire -x 
1 --mode DetectNet_v2 -i https --async --output_path out 
--postprocessing_config /home/diycam/Desktop/Desktop_Items/nvidia_triton_server/trion_work/models/clustering_config.prototxt



# p1=subprocess.Popen("docker run --gpus 1 --rm --shm-size=1g --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -p 
8000:8000 -p 8001:8001 -p 8002:8002 -v $(pwd)/model_respository:/models nvcr.io/nvidia/tritonserver:21.06-py3 tritonserver
 --model-repository=/models --strict-model-config=false --grpc-infer-allocation-pool-size=16",shell=True)